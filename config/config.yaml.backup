bucket: nn-uct

paths:
  main_script: "~/deepEMIA/main.py"
  split_dir: "~/split_dir"
  category_json: "~/deepEMIA/dataset_info.json"
  eta_file: "~/deepEMIA/config/eta_data.json"
  logs_dir: "~/logs"
  output_dir: "~/deepEMIA/output"
  local_dataset_root: "~"

scale_bar_rois:
  default:
    x_start_factor: 0.7
    y_start_factor: 0.05
    width_factor: 1
    height_factor: 0.05

scalebar_thresholds:
  intensity: 100
  proximity: 50

measure_contrast_distribution: false

rcnn_hyperparameters:
  # Default hyperparameters used for all datasets when no dataset-specific settings exist
  default:
    R50:
      base_lr: 0.00025
      ims_per_batch: 2
      warmup_iters: 1000
      gamma: 0.1
      batch_size_per_image: 64
    R101:
      base_lr: 0.00025
      ims_per_batch: 2
      warmup_iters: 1000
      gamma: 0.1
      batch_size_per_image: 64
  # Global best hyperparameters (used when no dataset-specific best exists)
  best:
    R50: {}
    R101: {}

inference_settings:
  use_class_specific_inference: true
  iterative_stopping:
    min_total_masks: 10
    min_relative_increase: 0.25
    max_consecutive_zero: 1
    min_iterations: 2
  
  # Confidence threshold mode: 'manual' or 'auto'
  confidence_mode: 'auto'  # Set to 'manual' to use class_specific_settings thresholds
  
  class_specific_settings:
    class_0:  # Large particles
      confidence_threshold: 0.5
      iou_threshold: 0.7
      min_size: 25
      min_size_factor: 0.0001  # 0.01% of image area
    class_1:  # Small particles
      confidence_threshold: 0.3
      iou_threshold: 0.5
      min_size: 3  # Absolute minimum
      min_size_factor: 0.000005  # 0.0005% of image area (very aggressive)
      use_multiscale: true
  
  # Multi-model ensemble settings
  ensemble_settings:
    enabled: true
    small_classes_only: true  # Only use ensemble for small particles
    weights:
      R50: 0.6  # R50 better for small particles
      R101: 0.4  # R101 better for context
  
  # Multi-scale settings
  multiscale_settings:
    baseline_scales: [0.7, 1.0, 1.5, 2.0]  # Standard scales
    aggressive_scales: [1.0, 1.5, 2.0, 2.5, 3.0]  # For very small particles
    max_scale: 3.0

  # Tile-based inference settings
  use_tile_based_inference: true  # Enable for small particles
  
  tile_settings:
    tile_size: 512  # Base tile size before upscaling
    overlap_ratio: 0.1  # 10% overlap (reduced from 20%)
    upscale_factor: 2.0  # 2x upscaling for small particles
    edge_filter_enabled: true
    
    # Run tiling for all classes (not just small ones)
    classes_using_tiling: [0, 1]  # All classes use tiling
    
    # GPU batch processing for tiles
    tile_batch_size: 2               # Reduce from 4 to 2

# L4 GPU Performance Optimizations
# Specifically tuned for g2-standard-4 (4 vCPUs, 16GB RAM, 1x NVIDIA L4)
l4_performance_optimizations:
  # Batch processing (conservative for 16GB RAM)
  inference_batch_size: 1          # Reduce from 3
  measurement_batch_size: 3        # Reduce from 5
  
  # Memory management for L4 GPU (22GB VRAM)
  clear_cache_frequency: 3         # More frequent cleanup (from 5)
  clear_cache_after_tiles: true    # Enable per-batch cleanup
  max_memory_usage: 0.8           # Use max 80% of available GPU memory
  
  # Threading (optimized for 4 vCPUs)
  max_worker_threads: 3           # Use 3 threads, leave 1 for main process
  enable_parallel_image_loading: true
  enable_parallel_mask_processing: true
  
  # Model optimizations for L4
  use_mixed_precision: true       # Use AMP for 30-50% speedup on L4
  enable_gpu_optimizations: true  # Enable cudnn.benchmark, etc.
  optimize_for_inference: true    # Disable gradients, set eval mode
  
  # I/O optimizations  
  stream_measurements_to_csv: true  # Stream instead of buffering all
  cleanup_individual_masks: true   # Remove individual mask files after completion