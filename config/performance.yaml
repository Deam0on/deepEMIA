# =============================================================================
# PERFORMANCE CONFIGURATION
# =============================================================================
# L4 GPU Performance Optimizations
# Specifically tuned for g2-standard-4 (4 vCPUs, 16GB RAM, 1x NVIDIA L4)

l4_performance_optimizations:
  # Batch processing (conservative for 16GB RAM)
  inference_batch_size: 1  # Reduce from 3 to prevent OOM
  measurement_batch_size: 3  # Reduce from 5
  
  # Memory management for L4 GPU (22GB VRAM)
  clear_cache_frequency: 3  # More frequent cleanup (from 5)
  clear_cache_after_tiles: true  # Enable per-batch cleanup
  max_memory_usage: 0.8  # Use max 80% of available GPU memory
  
  # Threading (optimized for 4 vCPUs)
  max_worker_threads: 3  # Use 3 threads, leave 1 for main process
  enable_parallel_image_loading: true
  enable_parallel_mask_processing: true
  
  # Model optimizations for L4
  use_mixed_precision: true  # Use AMP for 30-50% speedup on L4
  enable_gpu_optimizations: true  # Enable cudnn.benchmark, etc.
  optimize_for_inference: true  # Disable gradients, set eval mode
  
  # I/O optimizations  
  stream_measurements_to_csv: true  # Stream instead of buffering all
  cleanup_individual_masks: true  # Remove individual mask files after completion
